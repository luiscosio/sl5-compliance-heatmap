# SL5 Compliance Heatmap - AI Lab Security Monitoring

[![Deployed on Vercel](https://img.shields.io/badge/Deployed%20on-Vercel-black?style=for-the-badge&logo=vercel)](https://vercel.com/luiscosios-projects/v0-heatmap)

## Overview

Track Security Level 5 (SL5) compliance of major AI labs with this interactive heatmap. Data is derived from open-source public information, updated daily using advanced LLMs to provide the latest insights into frontier model security.

This project monitors the security posture of major AI laboratories (OpenAI, Anthropic, Google, xAI, Meta) against the security framework outlined in the RAND report "Securing AI Model Weights". The system evaluates compliance across five security levels (SL1-SL5), from basic security measures to advanced nation-state level protections.

## Key Features

- **Real-time Compliance Tracking**: Monitor AI lab security compliance across multiple categories
- **Automated Data Updates**: Leverages Claude AI to continuously update compliance scores from public sources
- **Interactive Heatmap Visualization**: Easy-to-understand visual representation of security postures
- **Comprehensive Security Framework**: Based on RAND's "Securing AI Model Weights" research
- **Multi-Lab Coverage**: Tracks OpenAI, Anthropic, Google, xAI, and Meta

## Security Levels

The system tracks compliance across five security levels:

- **SL1**: Protection against amateur attempts (hobbyist hackers, untargeted attacks)
- **SL2**: Enhanced security measures for more sophisticated threats
- **SL3**: Advanced protections against skilled adversaries
- **SL4**: High-security measures for state-level threats
- **SL5**: Maximum security for nation-state level adversaries

## Automated Data Updates

The project includes a Python script (`data/update.py`) that automatically:

- Queries the Anthropic Claude API with web search capabilities
- Evaluates each AI lab's public security posture against specific controls
- Scores compliance in 25% increments (0, 25, 50, 75, 100)
- Provides justifications and source URLs for each assessment
- Updates the compliance database with the latest information

### Running Data Updates

\`\`\`bash
# Install Python dependencies
pip install -r requirements.txt

# Set your Anthropic API key
export ANTHROPIC_API_KEY=your_api_key_here

# Run the update script
python data/update.py

# For testing (limit number of controls processed)
python data/update.py --limit 5
\`\`\`

## Tech Stack

- **Frontend**: Next.js 15, React 19, TypeScript
- **Styling**: Tailwind CSS with shadcn/ui components
- **Data Visualization**: Recharts for heatmap rendering
- **Backend**: Python script with Anthropic Claude API
- **Data Storage**: JSON-based compliance database
- **Deployment**: Vercel

## Development

\`\`\`bash
# Install dependencies
npm install

# Run development server
npm run dev

# Build for production
npm run build

# Start production server
npm start
\`\`\`

## Data Structure

The compliance data is organized hierarchically:
- **Security Levels** (SL1-SL5)
  - **Categories** (Weight Security, Network Security, etc.)
    - **Subcategories** (Weight Storage, Access Control, etc.)
      - **Controls** (Specific security measures)
        - **Lab Compliance** (Scores, justifications, sources for each AI lab)

## Live Demo

**[https://sl5.luiscos.io/](https://sl5.luiscos.io/)**

## Contributing

This project uses automated data collection, but manual verification and updates are welcome. The compliance scores are generated by AI and should be reviewed for accuracy.

## Disclaimer

This project is for informational purposes only. Compliance scores are derived from publicly available information and AI analysis. They should not be considered definitive assessments of actual security postures. Organizations should conduct proper security audits for accurate evaluations.

## License

This project is built using v0.dev and automatically synced with the deployment platform.
